{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d762feed-a001-4688-8ede-04d29ea176d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import psycopg2\n",
    "import uuid\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aab5ea26-f708-41a6-9051-07e42526ae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# get ChatGPT key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# get database configuration\n",
    "db_config = {\n",
    "    \"host\": os.getenv(\"DB_HOST\"),\n",
    "    \"database\": os.getenv(\"DB_NAME\"),\n",
    "    \"user\": os.getenv(\"DB_USER\"),\n",
    "    \"password\": os.getenv(\"DB_PASSWORD\")\n",
    "}\n",
    "\n",
    "# define configuration variables for API call\n",
    "completion_config = {\n",
    "    \"GPT_MODEL\": \"gpt-4o-mini\",\n",
    "    \"TEMPERATURE\": 0,\n",
    "    \"MAX_TOKENS\": 500,\n",
    "    \"MAX_INPUT_TOKENS\": 8000, # Adjust based on the model's token limit\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42e91da7-78c4-41b5-a1f7-698e308ed7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PostgreSQL Version: PostgreSQL 16.4 (Ubuntu 16.4-0ubuntu0.24.04.2) on x86_64-pc-linux-gnu, compiled by gcc (Ubuntu 13.2.0-23ubuntu4) 13.2.0, 64-bit\n"
     ]
    }
   ],
   "source": [
    "# test db connection\n",
    "with psycopg2.connect(**db_config) as conn:\n",
    "    with conn.cursor() as cursor:\n",
    "        cursor.execute(\"SELECT version();\")\n",
    "        version = cursor.fetchone()\n",
    "        print(\"PostgreSQL Version:\", version[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f809e7dd-1777-48b3-8d12-e1b6999f10d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.encoding_for_model(completion_config[\"GPT_MODEL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2410100d-31dd-45c1-9ee5-7b0bc70e3498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete(messages, **kwargs):\n",
    "    # Load configuration settings and allow overrides via kwargs\n",
    "    model = kwargs.get(\"model\", completion_config[\"GPT_MODEL\"])\n",
    "    temperature = kwargs.get(\"temperature\", completion_config[\"TEMPERATURE\"])\n",
    "    max_tokens = kwargs.get(\"max_tokens\", completion_config[\"MAX_TOKENS\"])\n",
    "    max_input_tokens = kwargs.get(\"max_input_tokens\", completion_config[\"MAX_INPUT_TOKENS\"])\n",
    "\n",
    "    # Calculate total token count for input messages\n",
    "    total_tokens = sum(len(encoding.encode(msg[\"content\"])) for msg in messages)\n",
    "    token_usage = total_tokens + max_tokens\n",
    "\n",
    "    # Check if token usage is close to the limit (90% warning)\n",
    "    warning_threshold = int(max_input_tokens * 0.9)\n",
    "    if token_usage > warning threshold:\n",
    "        print(f\"WARNING: Token usage is at {token_usage}/{max_input_tokens} tokens (90% of the limit).\")\n",
    "\n",
    "    # Check if input tokens exceed the limit\n",
    "    if token_usage > max_input_tokens:\n",
    "        raise ValueError(\"Input messages exceed the maximum allowed token limit.\")\n",
    "    \n",
    "    # Make the API call\n",
    "    try:\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model = model,\n",
    "            messages = messages,\n",
    "            temperature = temperature,\n",
    "            max_tokens = max_tokens,\n",
    "        )\n",
    "        return completion\n",
    "\n",
    "    except openai.error.OpenAIError as e:\n",
    "        print(\"Error during API call:\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd97bb5-828d-4196-93bd-a36443b43f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Assistant:\n",
    "    def __init__(self):\n",
    "        self.session_id = None\n",
    "        self.messages = []\n",
    "        self.start_new_session()\n",
    "\n",
    "    def start_new_session(self):\n",
    "        \"\"\"Start a new session with a unique session ID.\"\"\"\n",
    "        self.session_id = str(uuid.uuid4())\n",
    "        print(f\"Started a new session with ID: {self.session_id}\")\n",
    "\n",
    "    def create_conversation(self, user_id, system_prompt):\n",
    "        \"\"\"Create a new conversation with the given system prompt\"\"\"\n",
    "        with psycopg2.connect(**db_config) as conn:\n",
    "            with conn.cursor() as cursor:\n",
    "                cursor.execute(\n",
    "                    \"\"\"\n",
    "                    INSERT INTO conversations (user_id, session_id, system_prompt, depth, conv_status)\n",
    "                    VALUES (%s, %s, %s, %s, %s)\n",
    "                    RETURNING id;\n",
    "                    \"\"\",\n",
    "                    (user_id, self.session_id, system_prompt, 0, 'active')\n",
    "                )\n",
    "                conversation_id = cursor.fetchone()[0]\n",
    "                print(f\"Created a new conversation with ID: {conversation_id}\")\n",
    "                return conversation_id\n",
    "\n",
    "    def add_message(self, conversation_id, role, content, GPTmodel):\n",
    "        \"\"\"Store a message in the database with accurate token counting.\"\"\"\n",
    "        with psycopg2.connect(**db_config) as conn:\n",
    "            with conn.cursor() as cursor:\n",
    "                # Count tokens using the OpenAI tokenizer\n",
    "                encoding = tiktoken.encoding_for_model(GPTmodel)\n",
    "                token_count = len(encoding.encode(content))\n",
    "\n",
    "                # Insert the message into the database\n",
    "                cursor.execute(\n",
    "                    \"\"\"\n",
    "                    INSERT INTO messages (conversation_id, role, content, token_count)\n",
    "                    VALUES (%s, %s, %s, %s);\n",
    "                    \"\"\",\n",
    "                    (conversation_id, role, content, token_count)\n",
    "                )\n",
    "                print(f\"Added message to conversation {conversation_id} with {token_count} tokens.\")\n",
    "\n",
    "    def load_history(self, conversation_id):\n",
    "        \"\"\"Load the entire message history of a conversation\"\"\"\n",
    "        with psycopg2.connect(**db_config) as conn:\n",
    "            with conn.cursor() as cursor:\n",
    "                cursor.execute(\n",
    "                    \"\"\"\n",
    "                    SELECT role, content FROM messages\n",
    "                    WHERE conversation_id = %s\n",
    "                    ORDER BY id;\n",
    "                    \"\"\",\n",
    "                    (conversation_id,)\n",
    "                )\n",
    "                history = cursor.fetchall()\n",
    "                return [{\"role\": role, \"content\": content} for role, content in history]\n",
    "    \n",
    "    def query(self, conversation_id, user_input):\n",
    "        \"\"\" Handle a user query and make API call.\"\"\"\n",
    "        self.add_message(conversation_id, \"user\", user_input)\n",
    "\n",
    "        # Load the full conversation history\n",
    "        self.messages = self.load_history(conversation_id)\n",
    "        \n",
    "        # Query the API\n",
    "        try:\n",
    "            completion = complete(self.messages, **kwargs)\n",
    "            content = completion.choices[0].message[\"content\"]\n",
    "\n",
    "            # Add the assistant's response to the conversation history\n",
    "            self.add_message(conversation_id, \"assistant\", content)\n",
    "\n",
    "            # Print and returnn the assistant's response\n",
    "            print(content)\n",
    "            return content\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error during API call:\", e)\n",
    "            return \"An error occurred while processing your request.\"\n",
    "\n",
    "    def replay_with_modified_prompt(self, conversation_id, new_system_prompt, user_id):\n",
    "        \"\"\"Replay the conversation history with a new system prompt\"\"\"\n",
    "        # Load the original conversation history\n",
    "        history = self.load_history(conversation_id)\n",
    "\n",
    "        # Create a new conversation under the current session\n",
    "        new_conversation_id = self.create_conversation(user_id, new_system_prompt)\n",
    "\n",
    "        # Add the new system prompt\n",
    "        self.add_message(new_conversation_id, \"system\", new_system_prompt)\n",
    "\n",
    "        # Replay user messages with the new system prompt\n",
    "        for message in history:\n",
    "            if message[\"role\"] == \"user\":\n",
    "                user_input = message[\"content\"]\n",
    "                self.query(new_conversation_id, user_input)\n",
    "\n",
    "        print(f\"Replayed conversation created with ID: {new_conversation_id}\")\n",
    "        return new_conversation_id\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e98d5a-ddc4-4c8f-aee2-332e1c8e0641",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = Assistant()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2678d102-dda8-4fb5-ad74-261fc7059f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
